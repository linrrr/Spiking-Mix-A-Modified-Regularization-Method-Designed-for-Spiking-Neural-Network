# Spiking-Mix-A-Modified-Regularization-Method-Designed-for-Spiking-Neural-Network
The advent of data augmentation attracts a lot of  attention on how to handle unstructured data. Data  augmentation makes it easier to mine the essential data to  extract more useful information.

[Article Link]  <br>
https://ieeexplore.ieee.org/document/10393072 <br>

[Reference]
 <br>[1] W. Maass, “Networks of spiking neurons: The third generation of neural network models,” Neural Networks, vol. 10, no. 9, pp. 1659–1671, 1998. 
 <br>[2] J. Jeong, S. Park, M. Kim, H. Lee, D. Kim, and J. Shin, “Smoothmix: Training confidence-calibrated smoothed classifiers for certified robustness”, in Advances in Neural Information Processing Systems.M. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang, and J. Vaughan,Eds., 35th Conference on Neural Information Processing Systems(NeurIPS), Dec 06-14, 2021. 
 <br>[3] J. Kim, W. Choo, and H. O. Song, “Puzzle mix: Exploiting saliencyand local statistics for optimal mixup,” in Proceedings of MachineLearning Research, H. Daume and A. Singh, Eds., vol. 119,International Conference on Machine Learning (ICML), Jul 13-18,2020.
 <br>[4] H. Zhang, M. Ciss´e, Y. N. Dauphin, and D. Lopez-Paz, “Mixup: Beyond empirical risk minimization,” vol. abs/1710.09412. [Online] Available: https://doi.org/10.48550/arXiv.1710.09412.
 <br>[5] S. Yun, D. Han, S. J. Oh, S. Chun, J. Choe, and Y. Yoo, “Cutmix:Regularization strategy to train strong classifiers with localizablefeatures,” in IEEE International Conference on Computer Vision.IEEE; IEEE Comp Soc; CVF, pp. 6022–6031, IEEE/CVFInternational Conference on Computer Vision (ICCV), Seoul, SouthKorea, Oct 27-Nov 02, 2019. 
 <br>[6] T. Devries and G. W. Taylor, “Improved regularization of convolutional neural networks with cutout,” vol. abs/1708.04552.[Online]. Available: https://arxiv.org/abs/1708.04552. 
 <br>[7] Z. Zhong, L. Zheng, G. Kang, S. Li, and Y. Yang, “ Random erasingdata augmentation,” in AAAI Conference on Artificial Intelligence,vol. 34. Assoc Advancement Artificial Intelligence, pp. 13 001–13008, 34th AAAI Conference on Artificial Intelligence/32nd Innovative Applications of Artificial Intelligence Conference/10th AAAI Symposium on Educational Advances in Artificial Intelligence, New York, NY, Feb 07-12, 2020.
 <br>[8] G. Ghiasi, T. Lin, and Q. V. Le, “Dropblock: A regularization method for convolutional networks,” Advances in Neural Information Processing Systems, S. Bengio, H. Wallach, H. Larochelle, K.Grauman, N. CesaBianchi, and R. Garnett, Eds., vol. 31, 32nd Conference on Neural Information Processing Systems (NIPS),Montreal, Canada, Dec 02-08, 2018.
 <br>[9] X. Gastaldi, “Shake-shake regularization,” vol. abs/1705.07485.[Online]. Available: https://arxiv.org/abs/1705.07485. 
 <br>[10] Y. Yamada, M. Iwamura, and K. Kise, “Shakedrop regularization,”IEEE Access, vol. 7, pp.186 126–186 136.
 <br>[11] L.-Y. Niu and Y. Wei, “Cirm-snn: Certainty interval reset mechanism spiking neuron for enabling high accuracy spiking neural network,”Neural Processing Letters, vol. 55, no. 6, pp. 7561–7582. Apr 14,2023. 
 <br>[12] S. Zagoruyko and N. Komodakis, “Wide residual networks,” vol.abs/1605.07146. [Online] Available: https://doi.org/10.48550/arXiv.1605.07146.
 <br>[13] S. Thorpe, A. Delorme, and R. Van Rullen, “Spike-based strategies for rapid processing,” Neural Networks, vol. 14, no. 6-7, SI, pp. 715–725, Jul-Sep 2001. 
 <br>[14] N. Caporale and Y. Dan, “Spike timing-dependent plasticity: A hebbian learning rule,” Annual Review of Neuroscience, vol. 31, pp.25–46, 2008.
 <br>[15] B. Drukarch, H. A. Holland, M. Velichkov, J. J. G. Geurts, P. Voorn,G. Glas, and H. W. de Regt, “Thinking about the nerve impulse: A critical analysis of the electricity-centered conception of nerve excitability,” Process In Neurobiology, vol.169, pp.172–185, Oct 2018. 
 <br>[16] K.Efthymiadis,“fashion-mnist”. [Online] Available: https://github.com/kefth/fashion-mnist, 2019.
 <br>[17] C. Lee, S. S. Sarwar, and K. Roy, “Enabling spike based backpropagation in state-of-the-art deep neural network architectures,” vol. abs/1903.06379. [Online] Available: https://doi.org/10.48550/arXiv.1903.06379.
 <br>[18] V. Nair and G. E. Hinton, “Rectified linear units improve restricted boltzmann machines,” in ICML, vol. 27, pp. 807–814, 2010.
 <br>[19] A. F. M. S. Uddin, M. S. Monira, W. Shin, T. Chung, and S. Bae,“Saliencymix: A saliency guided data augmentation strategy for better regularization”, vol. abs/2006.01791. [Online]Available: https://doi.org/10.48550/ arXiv.2006.01791.
 <br>[20] X. Yu, Z. Yu, and S. Ramalingam, “Learning strict identity mappings in deep residual networks” in 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. IEEE; CVF; IEEE Comp Soc, pp. 4432–4440, 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, Jun 18-23,2018.
 <br>[21] Jie Hu and Li Shen and Samuel Albanie and Gang Sun and Enhua Wu,“Squeeze-and-Excitation Networks”, vol. abs/1709.01507. [Online] Available: https://doi.org/10.48550/arXiv.1709.01507.
 <br>[22] R.R. Selvaraju, A. Das, R. Vedantam, M. Cogswell, D. Parikh, and D.Batra, “Grad-cam: Why did you say that? visual explanations from deep networks via gradient-based localization”, [Online] Available:https://doi.org/10.48550/arXiv.1610.02391. 
 <br>[23] B. Zhou, A. Khosla, L. A., A. Oliva, and A. Torralba. Learning Deep Features for Discriminative Localization, in 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2921–2929.
 <br>[24] H. Li, Z. Xu, G. Taylor, and T. Goldstein, “Visualizing the loss landscape of neural nets”, [Online] Available: https://doi.org/10.48550/arXiv.1712.09913. 
 <br>[25] Z. Yao, A. Gholami, K. Keutzer, and M. W. Mahoney, “Pyhessian:Neural networks through the lens of the hessian”, in 2020 IEEE International Conference on Big Data (Big Data), pp. 581–59.
 <br>[26]Deng J , Dong W , Socher R ,et al.ImageNet: a Large-Scale Hierarchical Image Database[C]//2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2009), 20-25 June 2009, Miami, Florida, USA.IEEE, 2009.DOI:10.1109/CVPR.2009.5206848.
 <br>[27]Fang W, Chen Y, Ding J, et al. Spikingjelly: An open-source machine learning infrastructure platform for spike-based intelligence[J]. Science Advances, 2023, 9(40): eadi1480.
